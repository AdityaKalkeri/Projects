{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet analysis: Naive Bayes, LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPrVNAJ32hgK04KPRn5dZna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityakalkeri1/Projects/blob/NLP/Tweet_analysis_Naive_Bayes%2C_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_4LyV71eZoh"
      },
      "source": [
        "# Uploading Dataset to Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXOdZ1_pgCvS",
        "outputId": "eb201df4-1fe5-40ee-bdf1-54479d6a933f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cAuCtD3h6ox",
        "outputId": "1d3b54f8-59c6-40c3-b94e-afd370c3aca8"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/Datasets/'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " archive.zip  'GoIbibo India Hotels'  'NYC airbnb'  'Uber dataset'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYoM0ZiqiJe4",
        "outputId": "de78505f-e509-4706-d7cb-8796df89cc7a"
      },
      "source": [
        "!unzip 'gdrive/MyDrive/Datasets/archive.zip' -d 'Archive/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/MyDrive/Datasets/archive.zip\n",
            "replace Archive/training.1600000.processed.noemoticon.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Archive/training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgyoCiPgifO4"
      },
      "source": [
        "# Text Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ0MhjDclzq-"
      },
      "source": [
        "## 1. Cleaning the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQTZm7u-izS4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUWSX3s1jzZW"
      },
      "source": [
        "df = pd.read_csv('Archive/training.1600000.processed.noemoticon.csv', encoding = 'latin', header=None)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-cnD72zOj67v",
        "outputId": "3b8a8c16-ae84-4f1b-8e61-acc8f45a25e4"
      },
      "source": [
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AmandaMarie1028</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>TheWDBoards</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>bpbabe</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>tinydiamondz</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RyanTrevMorris</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  ...                                                  5\n",
              "0        0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1        0  ...  is upset that he can't update his Facebook by ...\n",
              "2        0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3        0  ...    my whole body feels itchy and like its on fire \n",
              "4        0  ...  @nationwideclass no, it's not behaving at all....\n",
              "...     ..  ...                                                ...\n",
              "1599995  4  ...  Just woke up. Having no school is the best fee...\n",
              "1599996  4  ...  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997  4  ...  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998  4  ...  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999  4  ...  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1600000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiU7FHZCkMSA"
      },
      "source": [
        "df.columns = ['Sentiment', 'ID', 'Date', 'Query', 'user', 'Text']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GbrQPUClIA_"
      },
      "source": [
        "df.drop(['ID', 'Date', 'Query', 'user'], axis =1, inplace = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "3IuLj931lPof",
        "outputId": "5ef6a8b1-3b0f-41ad-c731-563917546c25"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                               Text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_m19Vdztakj",
        "outputId": "c89f21e7-488d-4c63-9980-9c1c1c10abc4"
      },
      "source": [
        "(df['Text'] == 1).sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CGtG1yslR_f",
        "outputId": "6427c07d-d0c0-46f4-fb3b-f59cf3b60787"
      },
      "source": [
        "for i in range(10):\n",
        "  print(df['Text'][i])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
            "@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
            "my whole body feels itchy and like its on fire \n",
            "@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
            "@Kwesidei not the whole crew \n",
            "Need a hug \n",
            "@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?\n",
            "@Tatiana_K nope they didn't have it \n",
            "@twittera que me muera ? \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1PpiV1GmLdq",
        "outputId": "37aaebc3-d1e1-4020-f7d6-fc78db65f1a4"
      },
      "source": [
        "for i in range(1080, 1090):\n",
        "  print(df['Text'][i])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@onlysweeter I don't know the dance. \n",
            "@laurwee_boo im ok I guess had a hard day \n",
            "Jade is looking for a new home...  http://apps.facebook.com/dogbook/profile/view/4744827\n",
            "damnnn! i missed 11:11 \n",
            "@sarahprout tweetfinder hates me  and I was having trouble with background on twitter,what do you think?\n",
            "@Twilighter4Life lol yeh ill be studying  stupid uni. only 2 more weeks and im on holidays! YAY! plus my birthday next week woot\n",
            "@transbay &quot;SFMTA Budget Proposal Hearing: tomorrow, April 7 at 2:00 pm (City Hall, Room 400). Sadly, I cannot attend.&quot; Me neither. \n",
            "is afraid that her G.I. notes will not read themselves. \n",
            "*Sigh* Rain??? Why did you decide to show up? Move away! You were not invited to the Tuesday-party  (this is not the start I hoped for)\n",
            "_secretgarden_ I haven't gotten any porn spammers  I don't check my followers, but haven't had any tweets like that.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjGyqoB6mIvO"
      },
      "source": [
        "We have to remove 'mentions' (Start with @), any websites, and numbers. We will use re to clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIBfj_cslXgP"
      },
      "source": [
        "import re\n",
        "def text_cleaner(row):\n",
        "  row = re.sub('@[a-zA-Z0-9_]+','', row)                                          #For removing usernames\n",
        "  row = re.sub('(http.+\\/\\/[a-zA-Z.]+\\/\\S+|http.+\\/\\/[a-zA-Z0-9.]+\\/)', '', row)  #For removing website names\n",
        "  row = re.sub('[0-9]+', '', row)                                                 #For removing numbers\n",
        "  row = re.sub('[*\\(\\)\\?!_%-]', '', row)                                           #For removing symbols\n",
        "\n",
        "  return row\n",
        "df['Text'] = df['Text'].apply(text_cleaner)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P1tbrQmqIeG",
        "outputId": "dcd7e377-3a26-462d-832e-0ff8aa435f4d"
      },
      "source": [
        "for i in range(10):\n",
        "  print(df['Text'][i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah\n",
            " I dived many times for the ball. Managed to save   The rest go out of bounds\n",
            "my whole body feels itchy and like its on fire \n",
            " no, it's not behaving at all. i'm mad. why am i here because I can't see you all over there. \n",
            " not the whole crew \n",
            "Need a hug \n",
            " hey  long time no see Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you \n",
            " nope they didn't have it \n",
            " que me muera  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPk5awSqQ7s",
        "outputId": "be26b82f-da46-46a3-c1e3-e313162bb368"
      },
      "source": [
        "for i in range(1080, 1090):\n",
        "  print(df['Text'][i])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I don't know the dance. \n",
            " im ok I guess had a hard day \n",
            "Jade is looking for a new home...  \n",
            "damnnn i missed : \n",
            " tweetfinder hates me  and I was having trouble with background on twitter,what do you think\n",
            " lol yeh ill be studying  stupid uni. only  more weeks and im on holidays YAY plus my birthday next week woot\n",
            " &quot;SFMTA Budget Proposal Hearing: tomorrow, April  at : pm City Hall, Room . Sadly, I cannot attend.&quot; Me neither. \n",
            "is afraid that her G.I. notes will not read themselves. \n",
            "Sigh Rain Why did you decide to show up Move away You were not invited to the Tuesdayparty  this is not the start I hoped for\n",
            "secretgarden I haven't gotten any porn spammers  I don't check my followers, but haven't had any tweets like that.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMxa-iBoqcEK"
      },
      "source": [
        "Now that data is cleaned, we take a look at sentiment values in the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "640hfPQ_qUyb",
        "outputId": "e1df9d06-e331-4ee8-a7c6-a250e93224e2"
      },
      "source": [
        "df['Sentiment'].unique()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4VBqI90qlqE"
      },
      "source": [
        "labels = df['Sentiment'].copy()\n",
        "texts = df['Text'].copy()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AokRXr-kquY0"
      },
      "source": [
        "labels[labels == 4] = 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8zthu3isxtE"
      },
      "source": [
        "Also, first 800000 rows are sentiment = 0, next are all sentiment = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6acAHb7vqv47",
        "outputId": "a4b2f3bd-07a7-4fdd-fc91-53e3545963fd"
      },
      "source": [
        "df['Sentiment'][:800000].unique()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfBlQSNzs3bi",
        "outputId": "ac610822-99a0-4ff1-f0d4-ffd6d4c8fcfe"
      },
      "source": [
        "df['Sentiment'][800000:].unique()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv6L7bCJtGyD"
      },
      "source": [
        "We will shuffle the dataset, and remove the earlier index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9s1wNsjs-La"
      },
      "source": [
        "data_input = [[x,y] for x,y in zip(texts, labels)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkCxeiGy-BN2"
      },
      "source": [
        "import random\n",
        "random.shuffle(data_input)\n",
        "\n",
        "text = [x[0] for x in data_input]\n",
        "labels = [x[1] for x in data_input]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPSBEp3Suvhp"
      },
      "source": [
        "Now we will separate labels and text, and split them into train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdWrmy0YtNWS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(text, labels, random_state = 10)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ldJsakHvz4e"
      },
      "source": [
        "# Naive Bayes and Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D-ITd2zvfog",
        "outputId": "2fec52f2-8c0d-44a3-a654-06ddba022ee1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(min_df = 5, ngram_range = (1,3)).fit(X_train)\n",
        "\n",
        "vocab = vect.get_feature_names()\n",
        "\n",
        "print('Length of vocab: ', len(vocab))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocab:  514454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHoLdFZYwZpg"
      },
      "source": [
        "X_train_vectorised = vect.transform(X_train)\n",
        "X_test_vectorised = vect.transform(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aye78GBpybCI",
        "outputId": "4516d999-0b0f-45d4-9a71-a36d3a0095d3"
      },
      "source": [
        "#Now training and evaluating Naive Bayes model\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "nb_model = MultinomialNB(alpha= 0.1).fit(X_train_vectorised, y_train)\n",
        "train_pred = nb_model.predict(X_train_vectorised)\n",
        "test_pred = nb_model.predict(X_test_vectorised)\n",
        "\n",
        "print('Training accuracy: ', accuracy_score(y_train,train_pred))\n",
        "print()\n",
        "print('Testing accuracy: ', accuracy_score(y_test,test_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy:  0.8427908333333334\n",
            "\n",
            "Testing accuracy:  0.80269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69c5-aw_zqJ4"
      },
      "source": [
        "Pretty good accuracy level, considering how simple the model is, and the training and prediction time was really quick, only 2 or 3 seconds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlEttmPrzoLc",
        "outputId": "f9baed12-1b95-47fd-9a13-63d6936f46d8"
      },
      "source": [
        "#Now training and testing logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(max_iter = 1000).fit(X_train_vectorised, y_train)\n",
        "train_pred = lr_model.predict(X_train_vectorised)\n",
        "test_pred = lr_model.predict(X_test_vectorised)\n",
        "\n",
        "print('Training accuracy: ', accuracy_score(y_train,train_pred))\n",
        "print()\n",
        "print('Testing accuracy: ', accuracy_score(y_test,test_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training accuracy:  0.9148441666666667\n",
            "\n",
            "Testing accuracy:  0.8143525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AWPNrAQ2-7d"
      },
      "source": [
        "Model is overfitting, plus took around 10 mins to train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8CoY0T43SEn"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzvLzXY0zlwu"
      },
      "source": [
        "#First Tokenizing the texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1HJFbaO372z"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houJyXDm4PAK",
        "outputId": "fb18e976-3dd3-4b47-bef0-e25d341c6d05"
      },
      "source": [
        "#Tokenizer\n",
        "tokenizer = Tokenizer(num_words = 2000,oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "print('Length of vocab: ', len(word_index))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocab:  271740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9sJe59_408z"
      },
      "source": [
        "#Converting the sentences to tokens\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OPO_7qPAVBc"
      },
      "source": [
        "max_len = 50                    #max length of a tweet"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQRk2XnC5r8L"
      },
      "source": [
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_len, truncating = 'post')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZTGQJLY6Cn6"
      },
      "source": [
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_len, truncating = 'post')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzEK7nvW6Vqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda1ea04-1071-4c21-b589-a6448076f6bd"
      },
      "source": [
        "#Defining model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "model = Sequential([\n",
        "                    Embedding(2000, 64, input_length = max_len),\n",
        "                    LSTM(64, dropout = 0.2, recurrent_dropout = 0.2),\n",
        "                    Dense(1, activation = 'sigmoid')\n",
        "])\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5sKbtLI7IfR",
        "outputId": "9a49841f-e1a8-4a90-c9de-de68ecd5a0d9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 64)            128000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 161,089\n",
            "Trainable params: 161,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj1gZX2fP1Rn",
        "outputId": "f07d7fdf-bd17-460a-d57b-dd9be7f5cb43"
      },
      "source": [
        "X_train_pad.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFXr4Uwmd06-",
        "outputId": "de995b37-13b7-4fb1-f402-81f734a8d5f1"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mavgt2UsP5Tj"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_train= y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmAhtFv8KN4"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = tf.keras.losses.binary_crossentropy,\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CagLUxJ_8o0A",
        "outputId": "e6aa6f4f-757f-4406-8c8e-f0917c80e24f"
      },
      "source": [
        "history = model.fit(X_train_pad, y_train, epochs = 1, validation_data=(X_test_pad, y_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37500/37500 [==============================] - 2789s 74ms/step - loss: 0.4075 - accuracy: 0.8120 - val_loss: 0.4047 - val_accuracy: 0.8134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsIEGrz59miY"
      },
      "source": [
        "def predict_sent(sentence):\n",
        "\n",
        "  tokens = tokenizer.texts_to_sequences([sentence])\n",
        "  sentence_pad = pad_sequences(tokens, maxlen=max_len, truncating = 'post')\n",
        "  pred = model.predict(sentence_pad)\n",
        "  print(pred)\n",
        "  if pred <=0.5:\n",
        "    print('Sentence sentiment is negative')\n",
        "  else:\n",
        "    print('Sentence sentiment is positive')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVNo03t0dkUU",
        "outputId": "57cb7137-4cfe-40c0-974f-a7d1d1cdf852"
      },
      "source": [
        "predict_sent('I am happy')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99172103]]\n",
            "Sentence sentiment is positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVsRTlSdgv0e",
        "outputId": "77bd3270-819e-4f42-e325-be57292e927f"
      },
      "source": [
        "predict_sent('I am sad')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00293928]]\n",
            "Sentence sentiment is negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqAvRUW1hG9u",
        "outputId": "b14e6ab0-55f7-4ede-e3e6-a25069004747"
      },
      "source": [
        "predict_sent('I am happy that you got the job, but i will be sad you are going to leave')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.06848097]]\n",
            "Sentence sentiment is negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWchYQghhLV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}